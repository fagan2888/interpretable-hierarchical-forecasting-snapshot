# **Literature Research Scan**

**Source:** DBLP Computer science bibliography

**Date:** 2020-05-12

**Search Terms:** (explain OR interpret) AND predictions

**Search Criteria:** Focus on explanation methods via feature attribution, not on interpretable models. If focus is on application, then it must be on time series.

**Results:** 72 publications were scanned by title and abstract, 21 were kept.  

-----

## **Accepted Publications**

### **AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models**
Eric Wallace and
Jens Tuyls and
Junlin Wang and
Sanjay Subramanian and
Matt Gardner and
Sameer Singh. (2019). AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models. *Proceedings of the 2019 Conference on Empirical Methods in Natural
Language Processing and the 9th International Joint Conference on
Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
November 3-7, 2019 - System Demonstrations*

**Comment:** Features overview over some attribution methods.

### **"What are You Listening to?" Explaining Predictions of Deep Machine Listening Systems**
Saumitra Mishra and
Bob L. Sturm and
Simon Dixon. (2018). "What are You Listening to?" Explaining Predictions of Deep Machine Listening Systems. *26th European Signal Processing Conference, {EUSIPCO} 2018, Roma,
Italy, September 3-7, 2018*

**Comment:** Related to attribution in wider sense.

### **A Model-Agnostic Approach for Explaining the Predictions on Clustered Data**
Zihan Zhou and
Mingxuan Sun and
Jianhua Chen. (2019). A Model-Agnostic Approach for Explaining the Predictions on Clustered Data. *2019 {IEEE} International Conference on Data Mining, {ICDM} 2019,
Beijing, China, November 8-11, 2019*

**Comment:** Related to attribution via local surrogate model.

### **Explaining Therapy Predictions with Layer-Wise Relevance Propagation in Neural Networks**
Yinchong Yang and
Volker Tresp and
Marius Wunderle and
Peter A. Fasching. (2018). Explaining Therapy Predictions with Layer-Wise Relevance Propagation in Neural Networks. *{IEEE} International Conference on Healthcare Informatics, {ICHI}
2018, New York City, NY, USA, June 4-7, 2018*

**Comment:** LWRP is an attribution technique.

### **Hierarchical interpretations for neural network predictions**
Chandan Singh and
W. James Murdoch and
Bin Yu. (2019). Hierarchical interpretations for neural network predictions. *7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019*

**Comment:** Features attribution in a wider sense.

### **BayesGrad: Explaining Predictions of Graph Convolutional Networks**
Hirotaka Akita and
Kosuke Nakago and
Tomoki Komatsu and
Yohei Sugawara and
Shin{-}ichi Maeda and
Yukino Baba and
Hisashi Kashima. (2018). BayesGrad: Explaining Predictions of Graph Convolutional Networks. *Neural Information Processing - 25th International Conference, {ICONIP}
2018, Siem Reap, Cambodia, December 13-16, 2018, Proceedings, Part
{V}*

**Comment:** Could be related to feature attribution.

### **Explainable Deep Neural Networks for Multivariate Time Series Predictions**
Roy Assaf and
Anika Schumann. (2019). Explainable Deep Neural Networks for Multivariate Time Series Predictions. *Proceedings of the Twenty-Eighth International Joint Conference on
Artificial Intelligence, {IJCAI} 2019, Macao, China, August 10-16,
2019*

**Comment:** Saliency maps are related to feature attribution.

### **"Why Should I Trust You?": Explaining the Predictions of Any Classifier**
Marco T{\'{u}}lio Ribeiro and
Sameer Singh and
Carlos Guestrin. (2016). "Why Should I Trust You?": Explaining the Predictions of Any Classifier. *Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
13-17, 2016*

**Comment:** Theoretical and methodological contribution.

### **A Unified Approach to Interpreting Model Predictions**
Scott M. Lundberg and
Su{-}In Lee. (2017). A Unified Approach to Interpreting Model Predictions. *Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, 4-9 December 2017,
Long Beach, CA, {USA}*

**Comment:** Theoretical and methodological contribution.

### **Explaining Single Predictions: A Faster Method**
Gabriel Ferrettini and
Julien Aligon and
Chantal Soul{\'{e}}{-}Dupuy. (2020). Explaining Single Predictions: A Faster Method. *{SOFSEM} 2020: Theory and Practice of Computer Science - 46th International
Conference on Current Trends in Theory and Practice of Informatics,
{SOFSEM} 2020, Limassol, Cyprus, January 20-24, 2020, Proceedings*

**Comment:** About attribution techniques.

### **Understanding Patch-Based Learning by Explaining Predictions**
Christopher J. Anders and
Gr{\'{e}}goire Montavon and
Wojciech Samek and
Klaus{-}Robert M{\"{u}}ller. (2018). Understanding Patch-Based Learning by Explaining Predictions. *CoRR*

**Comment:** LWRP is an attribution technique.

### **Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions**
Milo Honegger. (2018). Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions. *CoRR*

**Comment:** Theory related to attribution.

### **Explaining individual predictions when features are dependent: More accurate approximations to Shapley values**
Kjersti Aas and
Martin Jullum and
Anders L{\o}land. (2019). Explaining individual predictions when features are dependent: More accurate approximations to Shapley values. *CoRR*

**Comment:** Theory about attribution.

### **Why should you trust my interpretation? Understanding uncertainty in LIME predictions**
Hui Fen Tan and
Kuangyan Song and
Madeilene Udell and
Yiming Sun and
Yujia Zhang. (2019). Why should you trust my interpretation? Understanding uncertainty in LIME predictions. *CoRR*

**Comment:** Related to attribution technique.

### **Explaining the Predictions of Any Image Classifier via Decision Trees**
Sheng Shi and
Xinfeng Zhang and
Haisheng Li and
Wei Fan. (2019). Explaining the Predictions of Any Image Classifier via Decision Trees. *CoRR*

**Comment:** Related to attribution via surrogates in a wider sense.

### **An unexpected unity among methods for interpreting model predictions**
Scott Lundberg and
Su{-}In Lee. (2016). An unexpected unity among methods for interpreting model predictions. *CoRR*

**Comment:** Theoretical contribution.

### **Interpreting the Predictions of Complex ML Models by Layer-wise Relevance Propagation**
Wojciech Samek and
Gr{\'{e}}goire Montavon and
Alexander Binder and
Sebastian Lapuschkin and
Klaus{-}Robert M{\"{u}}ller. (2016). Interpreting the Predictions of Complex ML Models by Layer-wise Relevance Propagation. *CoRR*

**Comment:** Theoretical and methodological contribution.

### **Not All Explanations Predict Satisfactorily, and Not All Good Predictions Explain**
Klaus G. Troitzsch. (2009). Not All Explanations Predict Satisfactorily, and Not All Good Predictions Explain. *J. Artificial Societies and Social Simulation*

**Comment:** Theory of model explanation.

### **Explaining prediction models and individual predictions with feature contributions**
Erik Strumbelj and
Igor Kononenko. (2014). Explaining prediction models and individual predictions with feature contributions. *Knowl. Inf. Syst.*

**Comment:** About feature attribution.

### **Explaining the Predictions of an Arbitrary Prediction Model: Feature Contributions and Quasi-nomograms**
Erik Strumbelj and
Igor Kononenko. (2018). Explaining the Predictions of an Arbitrary Prediction Model: Feature Contributions and Quasi-nomograms. *Human and Machine Learning - Visible, Explainable, Trustworthy and
Transparent*

**Comment:** About feature attribution.

### **Explanations for Attributing Deep Neural Network Predictions**
Ruth Fong and
Andrea Vedaldi. (2019). Explanations for Attributing Deep Neural Network Predictions. *Explainable {AI:} Interpreting, Explaining and Visualizing Deep Learning*

**Comment:** Theory and methods for feature attribution.

-----

## **Discarded Publications**

### **Deep Learning for Case-Based Reasoning Through Prototypes: A Neural Network That Explains Its Predictions**
Oscar Li and
Hao Liu and
Chaofan Chen and
Cynthia Rudin. (2018). Deep Learning for Case-Based Reasoning Through Prototypes: A Neural Network That Explains Its Predictions. *Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
(AAAI-18), the 30th innovative Applications of Artificial Intelligence
(IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
2-7, 2018*

**Comment:** Interpretable model, not explanation method.

### **Desiderata for Interpretability: Explaining Decision Tree Predictions with Counterfactuals**
Kacper Sokol and
Peter A. Flach. (2019). Desiderata for Interpretability: Explaining Decision Tree Predictions with Counterfactuals. *The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
2019, The Thirty-First Innovative Applications of Artificial Intelligence
Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
USA, January 27 - February 1, 2019*

**Comment:** About counterfactuals, not attributions.

### **Interpretable Neural Predictions with Differentiable Binary Variables**
Joost Bastings and
Wilker Aziz and
Ivan Titov. (2019). Interpretable Neural Predictions with Differentiable Binary Variables. *Proceedings of the 57th Conference of the Association for Computational
Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
Volume 1: Long Papers*

**Comment:** Interpretable model, not attribution.

### **Interpreting Black Box Predictions using Fisher Kernels**
Rajiv Khanna and
Been Kim and
Joydeep Ghosh and
Sanmi Koyejo. (2019). Interpreting Black Box Predictions using Fisher Kernels. *The 22nd International Conference on Artificial Intelligence and Statistics,
{AISTATS} 2019, 16-18 April 2019, Naha, Okinawa, Japan*

**Comment:** About instance importance, not attribution.

### **Interpretable Predictions of Clinical Outcomes with An Attention-based Recurrent Neural Network**
Ying Sha and
May D. Wang. (2017). Interpretable Predictions of Clinical Outcomes with An Attention-based Recurrent Neural Network. *Proceedings of the 8th {ACM} International Conference on Bioinformatics,
Computational Biology, and Health Informatics, {BCB} 2017, Boston,
MA, USA, August 20-23, 2017*

**Comment:** Interpretable model, not attribution.

### **Assessing K-Nearest Neighbours Algorithm for Simple, Interpretable Time-to-Event Survival Predictions Over a Range of Simulated Datasets**
Pavel Kroupa and
Caroline Morton and
Kerlann Le Calvez and
Matt Williams. (2019). Assessing K-Nearest Neighbours Algorithm for Simple, Interpretable Time-to-Event Survival Predictions Over a Range of Simulated Datasets. *32nd {IEEE} International Symposium on Computer-Based Medical Systems,
{CBMS} 2019, Cordoba, Spain, June 5-7, 2019*

**Comment:** Different topic and not about attribution.

### **Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data**
Yea{-}Seul Kim and
Katharina Reinecke and
Jessica Hullman. (2017). Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data. *Proceedings of the 2017 {CHI} Conference on Human Factors in Computing
Systems, Denver, CO, USA, May 06-11, 2017*

**Comment:** About visualisation.

### **The Interaction of Bayesian Pragmatics and Lexical Semantics in Linguistic Interpretation: Using Event-related Potentials to Investigate Hearers' Probabilistic Predictions**
Markus Werning and
Erica Cosentino. (2017). The Interaction of Bayesian Pragmatics and Lexical Semantics in Linguistic Interpretation: Using Event-related Potentials to Investigate Hearers' Probabilistic Predictions. *Proceedings of the 39th Annual Meeting of the Cognitive Science Society,
CogSci 2017, London, UK, 16-29 July 2017*

**Comment:** Different topic and not about attribution.

### **Explaining Computer Predictions with Augmented Appraisal Degrees**
Marcelo Loor and
Guy De Tr{\'{e}}. (2019). Explaining Computer Predictions with Augmented Appraisal Degrees. *Proceedings of the 11th Conference of the European Society for Fuzzy
Logic and Technology, {EUSFLAT} 2019, Prague, Czech Republic, September
9-13, 2019*

**Comment:** Not about attribution.

### **Explainable Predictions of Adverse Drug Events from Electronic Health Records Via Oracle Coaching**
Loes Crielaard and
Panagiotis Papapetrou. (2018). Explainable Predictions of Adverse Drug Events from Electronic Health Records Via Oracle Coaching. *2018 {IEEE} International Conference on Data Mining Workshops, {ICDM}
Workshops, Singapore, Singapore, November 17-20, 2018*

**Comment:** About global surrogate models, not about attribution.

### **Understanding Early Childhood Obesity via Interpretation of Machine Learning Model Predictions**
Xueqin Pang and
Christopher B. Forrest and
F{\'{e}}lice L{\^{e}}{-}Scherban and
Aaron J. Masino. (2019). Understanding Early Childhood Obesity via Interpretation of Machine Learning Model Predictions. *18th {IEEE} International Conference On Machine Learning And Applications,
{ICMLA} 2019, Boca Raton, FL, USA, December 16-19, 2019*

**Comment:** Focus on application other than time series.

### **Contrastive Relevance Propagation for Interpreting Predictions by a Single-Shot Object Detector**
Hideomi Tsunakawa and
Yoshitaka Kameya and
Hanju Lee and
Yosuke Shinya and
Naoki Mitsumoto. (2019). Contrastive Relevance Propagation for Interpreting Predictions by a Single-Shot Object Detector. *International Joint Conference on Neural Networks, {IJCNN} 2019 Budapest,
Hungary, July 14-19, 2019*

**Comment:** Related to LWRP, but to specific and not fit for use case.

### **Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking**
Gabriele Tolomei and
Fabrizio Silvestri and
Andrew Haines and
Mounia Lalmas. (2017). Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking. *Proceedings of the 23rd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13
- 17, 2017*

**Comment:** About counterfactual explanations, not feature attribution.

### **Visualizing and explaining deep learning predictions for pneumonia detection in pediatric chest radiographs**
Sivaramakrishnan Rajaraman and
Sema Candemir and
George R. Thoma and
Sameer K. Antani. (2019). Visualizing and explaining deep learning predictions for pneumonia detection in pediatric chest radiographs. *Medical Imaging 2019: Computer-Aided Diagnosis, San Diego, California,
United States, 16-21 February 2019*

**Comment:** Focus is on visualisation.

### **Using Aspect-Based Analysis for Explainable Sentiment Predictions**
Thiago De Sousa Silveira and
Hans Uszkoreit and
Renlong Ai. (2019). Using Aspect-Based Analysis for Explainable Sentiment Predictions. *Natural Language Processing and Chinese Computing - 8th {CCF} International
Conference, {NLPCC} 2019, Dunhuang, China, October 9-14, 2019, Proceedings,
Part {II}*

**Comment:** Not related to feature attribution.

### **Explaining Predictions from a Neural Network Ensemble One at a Time**
Robert Wall and
Padraig Cunningham and
Paul Walsh. (2002). Explaining Predictions from a Neural Network Ensemble One at a Time. *Principles of Data Mining and Knowledge Discovery, 6th European Conference,
{PKDD} 2002, Helsinki, Finland, August 19-23, 2002, Proceedings*

**Comment:** Not about attribution.

### **Explaining Predictions of Non-Linear Classifiers in NLP**
Leila Arras and
Franziska Horn and
Gr{\'{e}}goire Montavon and
Klaus{-}Robert M{\"{u}}ller and
Wojciech Samek. (2016). Explaining Predictions of Non-Linear Classifiers in NLP. *Proceedings of the 1st Workshop on Representation Learning for NLP,
Rep4NLP@ACL 2016, Berlin, Germany, August 11, 2016*

**Comment:** Different application (NLP).

### **Explaining Entity Resolution Predictions: Where are we and What needs to be done?**
Saravanan Thirumuruganathan and
Mourad Ouzzani and
Nan Tang. (2019). Explaining Entity Resolution Predictions: Where are we and What needs to be done?. *Proceedings of the Workshop on Human-In-the-Loop Data Analytics, HILDA@SIGMOD
2019, Amsterdam, The Netherlands, July 5, 2019*

**Comment:** Not about attribution.

### **NeuroMask: Explaining Predictions of Deep Neural Networks through Mask Learning**
Moustafa Alzantot and
Amy Widdicombe and
Simon Julier and
Mani B. Srivastava. (2019). NeuroMask: Explaining Predictions of Deep Neural Networks through Mask Learning. *{IEEE} International Conference on Smart Computing, {SMARTCOMP} 2019,
Washington, DC, USA, June 12-15, 2019*

**Comment:** Not about attribution.

### **Explaining Recurrent Neural Network Predictions in Sentiment Analysis**
Leila Arras and
Gr{\'{e}}goire Montavon and
Klaus{-}Robert M{\"{u}}ller and
Wojciech Samek. (2017). Explaining Recurrent Neural Network Predictions in Sentiment Analysis. *Proceedings of the 8th Workshop on Computational Approaches to Subjectivity,
Sentiment and Social Media Analysis, WASSA@EMNLP 2017, Copenhagen,
Denmark, September 8, 2017*

**Comment:** Different application.

### **Opening up the blackbox: an interpretable deep neural network-based classifier for cell-type specific enhancer predictions**
Seong Gon Kim and
Nawanol Theera{-}Ampornpunt and
Chih{-}Hao Fang and
Mrudul Harwani and
Ananth Grama and
Somali Chaterji. (2016). Opening up the blackbox: an interpretable deep neural network-based classifier for cell-type specific enhancer predictions. *{BMC} Syst. Biol.*

**Comment:** About interpretable models, not attribution.

### **Disorder Atlas: Web-based software for the proteome-based interpretation of intrinsic disorder predictions**
Michael Vincent and
Santiago Schnell. (2019). Disorder Atlas: Web-based software for the proteome-based interpretation of intrinsic disorder predictions. *Comput. Biol. Chem.*

**Comment:** Different application.

### **Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions**
Hai Ye and
Xin Jiang and
Zhunchen Luo and
Wenhan Chao. (2018). Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions. *CoRR*

**Comment:** Not about attribution.

### **Interpretable Credit Application Predictions With Counterfactual Explanations**
Rory Mc Grath and
Luca Costabello and
Chan Le Van and
Paul Sweeney and
Farbod Kamiab and
Zhao Shen and
Freddy L{\'{e}}cu{\'{e}}. (2018). Interpretable Credit Application Predictions With Counterfactual Explanations. *CoRR*

**Comment:** Not about attribution, but counterfactuals.

### **Explain to Fix: A Framework to Interpret and Correct DNN Object Detector Predictions**
Denis A. Gudovskiy and
Alec Hodgkinson and
Takuya Yamaguchi and
Yasunori Ishii and
Sotaro Tsukizawa. (2018). Explain to Fix: A Framework to Interpret and Correct DNN Object Detector Predictions. *CoRR*

**Comment:** Not about attribution.

### **Explainable Failure Predictions with RNN Classifiers based on Time Series Data**
Ioana Giurgiu and
Anika Schumann. (2019). Explainable Failure Predictions with RNN Classifiers based on Time Series Data. *CoRR*

**Comment:** Not about attribution.

### **Interpretation of machine learning predictions for patient outcomes in electronic health records**
William G. La Cava and
Christopher R. Bauer and
Jason H. Moore and
Sarah A. Pendergrass. (2019). Interpretation of machine learning predictions for patient outcomes in electronic health records. *CoRR*

**Comment:** Not about attribution, about feature importance, which is slightly different.

### **ExplaiNE: An Approach for Explaining Network Embedding-based Link Predictions**
Bo Kang and
Jefrey Lijffijt and
Tijl De Bie. (2019). ExplaiNE: An Approach for Explaining Network Embedding-based Link Predictions. *CoRR*

**Comment:** Not about attribution.

### **Interpretable and Differentially Private Predictions**
Frederik Harder and
Matthias Bauer and
Mijung Park. (2019). Interpretable and Differentially Private Predictions. *CoRR*

**Comment:** Different research question.

### **Explaining Predictions from Tree-based Boosting Ensembles**
Ana Lucic and
Hinda Haned and
Maarten de Rijke. (2019). Explaining Predictions from Tree-based Boosting Ensembles. *CoRR*

**Comment:** Not about attribution, about counterfactual explanations.

### **OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene Expression Data**
Md. Rezaul Karim and
Michael Cochez and
Oya Deniz Beyan and
Stefan Decker and
Christoph Lange. (2019). OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene Expression Data. *CoRR*

**Comment:** Different application.

### **Why X rather than Y? Explaining Neural Model' Predictions by Generating Intervention Counterfactual Samples**
Thai Le and
Suhang Wang and
Dongwon Lee. (2019). Why X rather than Y? Explaining Neural Model' Predictions by Generating Intervention Counterfactual Samples. *CoRR*

**Comment:** Not about attribution, about counterfactuals.

### **On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence**
Fabian Horst and
Djordje Slijepcevic and
Sebastian Lapuschkin and
Anna{-}Maria Raberger and
Matthias Zeppelzauer and
Wojciech Samek and
Christian Breiteneder and
Wolfgang I. Sch{\"{o}}llhorn and
Brian Horsak. (2019). On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence. *CoRR*

**Comment:** Different application.

### **Locally Interpretable Predictions of Parkinson's Disease Progression**
Qiaomei Li and
Rachel Cummings and
Yonatan Mintz. (2020). Locally Interpretable Predictions of Parkinson's Disease Progression. *CoRR*

**Comment:** Different application.

### **Interpretability Analysis for Named Entity Recognition to Understand System Predictions and How They Can Improve**
Oshin Agarwal and
Yinfei Yang and
Byron C. Wallace and
Ani Nenkova. (2020). Interpretability Analysis for Named Entity Recognition to Understand System Predictions and How They Can Improve. *CoRR*

**Comment:** Different application.

### **DeepCOVIDExplainer: Explainable COVID-19 Predictions Based on Chest X-ray Images**
Md. Rezaul Karim and
Till D{\"{o}}hmen and
Dietrich Rebholz{-}Schuhmann and
Stefan Decker and
Michael Cochez and
Oya Beyan. (2020). DeepCOVIDExplainer: Explainable COVID-19 Predictions Based on Chest X-ray Images. *CoRR*

**Comment:** Different application.

### **Interpretable Multi-Task Deep Neural Networks for Dynamic Predictions of Postoperative Complications**
Benjamin Shickel and
Tyler J. Loftus and
Shounak Datta and
Tezcan Ozrazgat{-}Baslanti and
Azra Bihorac and
Parisa Rashidi. (2020). Interpretable Multi-Task Deep Neural Networks for Dynamic Predictions of Postoperative Complications. *CoRR*

**Comment:** Different application.

### **WT5?! Training Text-to-Text Models to Explain their Predictions**
Sharan Narang and
Colin Raffel and
Katherine Lee and
Adam Roberts and
Noah Fiedel and
Karishma Malkan. (2020). WT5?! Training Text-to-Text Models to Explain their Predictions. *CoRR*

**Comment:** Different application, about interpretable models.

### **Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions**
Xiaochuang Han and
Byron C. Wallace and
Yulia Tsvetkov. (2020). Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions. *CoRR*

**Comment:** Not about attribution, but influential instance.

### **An Adversarial Approach for Explaining the Predictions of Deep Neural Networks**
Arash Rahnama and
Andrew Tseng. (2020). An Adversarial Approach for Explaining the Predictions of Deep Neural Networks. *CoRR*

**Comment:** Not about attribution, but feature importance.

### **A causal framework for explaining the predictions of black-box sequence-to-sequence models**
David Alvarez{-}Melis and
Tommi S. Jaakkola. (2017). A causal framework for explaining the predictions of black-box sequence-to-sequence models. *CoRR*

**Comment:** Not about attribution.

### **News-based forecasts of macroeconomic indicators: A semantic path model for interpretable predictions**
Stefan Feuerriegel and
Julius Gordon. (2019). News-based forecasts of macroeconomic indicators: A semantic path model for interpretable predictions. *Eur. J. Oper. Res.*

**Comment:** Not about attribution.

### **Explaining machine learning models in sales predictions**
Marko Bohanec and
Mirjana Kljajic Borstnar and
Marko Robnik{-}Sikonja. (2017). Explaining machine learning models in sales predictions. *Expert Syst. Appl.*

**Comment:** Different application.

### **Efficiently explaining the predictions of a probabilistic radial basis function classification network**
Marko Robnik{-}Sikonja and
Erik Strumbelj and
Igor Kononenko. (2013). Efficiently explaining the predictions of a probabilistic radial basis function classification network. *Intell. Data Anal.*

**Comment:** To specific technical application.

### **A Model for the Interpretation of Verbal Predictions**
Alf C. Zimmer. (1984). A Model for the Interpretation of Verbal Predictions. *Int. J. Man Mach. Stud.*

**Comment:** Different application.

### **An interpretable neural fuzzy inference system for predictions of underpricing in initial public offerings**
Di Wang and
Xiaolin Qian and
Chai Quek and
Ah{-}Hwee Tan and
Chunyan Miao and
Xiaofeng Zhang and
Geok See Ng and
You Zhou. (2018). An interpretable neural fuzzy inference system for predictions of underpricing in initial public offerings. *Neurocomputing*

**Comment:** Different application.

### **Electrostatic component of binding energy: Interpreting predictions from poisson-boltzmann equation and modeling protocols**
Arghya Chakravorty and
Lin Li and
Emil Alexov. (2016). Electrostatic component of binding energy: Interpreting predictions from poisson-boltzmann equation and modeling protocols. *J. Comput. Chem.*

**Comment:** Different application.

### **Visualization and Interpretation of Support Vector Machine Activity Predictions**
Jenny Balfer and
J{\"{u}}rgen Bajorath. (2015). Visualization and Interpretation of Support Vector Machine Activity Predictions. *J. Chem. Inf. Model.*

**Comment:** Different application.

### **Exploiting patterns to explain individual predictions**
Yunzhe Jia and
James Bailey and
Kotagiri Ramamohanarao and
Christopher Leckie and
Xingjun Ma. (2020). Exploiting patterns to explain individual predictions. *Knowl. Inf. Syst.*

**Comment:** Not about feature attribution.

### **Towards Explainable Process Predictions for Industry 4.0 in the DFKI-Smart-Lego-Factory**
Jana{-}Rebecca Rehse and
Nijat Mehdiyev and
Peter Fettke. (2019). Towards Explainable Process Predictions for Industry 4.0 in the DFKI-Smart-Lego-Factory. *{KI}*

**Comment:** Different application.

### **Understanding Patch-Based Learning of Video Data by Explaining Predictions**
Christopher J. Anders and
Gr{\'{e}}goire Montavon and
Wojciech Samek and
Klaus{-}Robert M{\"{u}}ller. (2019). Understanding Patch-Based Learning of Video Data by Explaining Predictions. *Explainable {AI:} Interpreting, Explaining and Visualizing Deep Learning*

**Comment:** Different application.