{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Script for Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import own code from other directory\n",
    "import sys\n",
    "sys.path.append(\"../../code/imputation\")\n",
    "\n",
    "from imputation_methods import impute_pmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(name=\"IMPUTATION\")\n",
    "logging.basicConfig()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Loading data.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Loading data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"delay_2020-05-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = pd.read_pickle(f\"../../data/processed/{filename}.pl\")\n",
    "if \"id\" in delay.columns:\n",
    "    delay = delay.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize all observations which do not have known or binary gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay.loc[(delay[\"gender\"]!=\"male\") & (delay[\"gender\"]!=\"female\"),\"gender\"] = \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove observations with negative reporting delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_neg = delay[delay[\"reporting_delay_hd\"]<0]\n",
    "delay = delay[(delay[\"reporting_delay_hd\"]>=0) | (delay[\"reporting_delay_hd\"].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding (Dummy Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Encoding as One-Hot variables.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Encoding as One-Hot variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dummy(X):\n",
    "    enc = OneHotEncoder(handle_unknown='error',sparse=False,drop=\"first\")\n",
    "    X_cat = X.select_dtypes(include=[object,\"category\"])\n",
    "    X_num = X.select_dtypes(exclude=[object,\"category\"])\n",
    "    X_trans = pd.DataFrame(enc.fit_transform(X_cat),columns=enc.get_feature_names(X_cat.columns),index=X.index)\n",
    "    X_dummy = pd.concat([X_num,X_trans],axis=1)\n",
    "    return X_dummy, enc, X_cat.columns\n",
    "\n",
    "def from_dummy(X, enc, cat_columns):\n",
    "    X_trans = X[enc.get_feature_names(cat_columns)]\n",
    "    X_num = X.drop(enc.get_feature_names(cat_columns),axis=1)\n",
    "    X_cat = pd.DataFrame(enc.inverse_transform(X_trans),columns=cat_columns,index=X.index)\n",
    "    X_res = pd.concat([X_num,X_cat],axis=1)\n",
    "    return X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_coded(X):\n",
    "    X = X.copy()\n",
    "    X_cat = X.select_dtypes(include=[object,\"category\"])\n",
    "    \n",
    "    # define\n",
    "    def map_to_int(series):\n",
    "        \"\"\"Convert non-numeric features to integer codes\"\"\"\n",
    "        series_cat=series.astype(\"category\")\n",
    "        mapping=dict(zip(series_cat,series_cat.cat.codes))\n",
    "        return series_cat.cat.codes, mapping\n",
    "\n",
    "    mappings = {feat:map_to_int(X[feat])[1] for feat in X_cat.columns}\n",
    "\n",
    "    # apply\n",
    "    for feat,mapping in mappings.items():\n",
    "        X[feat]=X[feat].replace(mapping)\n",
    "        \n",
    "    return X, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_labels = [\"reporting_delay_hd\",\"week_report\",\"weekday_report\",\"age\",\"gender\",\"state\"]\n",
    "delay_dummy , enc, enc_cats = to_dummy(delay[delay_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Performing imputation.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Performing imputation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute delay\n",
    "delay_imputed = impute_pmm(delay_dummy,\"reporting_delay_hd\",regressor=RandomForestRegressor(n_estimators=10),k_pmm=5,n=3)\n",
    "# round to next integer\n",
    "delay_imputed = delay_imputed.round()\n",
    "# compute day of onset by subtracting delay from day of report\n",
    "onset_imputed = delay_imputed.apply(lambda x: delay.loc[delay_imputed.index,\"day_report\"] - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor imputed values back into original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Reintegrating as delay dataframe.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Reintegrating as delay dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_ordered_weekday(col):\n",
    "    return col.astype(pd.CategoricalDtype(ordered=True)).cat.reorder_categories(\n",
    "        [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "# Concat columns\n",
    "delay_imp = delay.copy()\n",
    "for col in onset_imputed.columns:\n",
    "    delay_imp[col] = np.nan\n",
    "    delay_imp.loc[onset_imputed.index,col] = onset_imputed[col]\n",
    "\n",
    "# Pivot to long format\n",
    "delay_imp = delay_imp.melt(id_vars=delay_imp.drop([\"day_onset\"]+list(onset_imputed.columns),axis=1).columns,\n",
    "          value_vars=[\"day_onset\"]+list(onset_imputed.columns),var_name=\"imputation\",value_name=\"day_onset\")\n",
    "\n",
    "# Drop empty day onset rows\n",
    "delay_imp = delay_imp.dropna(subset=[\"day_onset\"]).sort_values(\"day_onset\")\n",
    "\n",
    "# Compute derived values for imputed rows\n",
    "delay_imp[\"imputation\"]= delay_imp[\"imputation\"].replace({\"day_onset\":\"original\"})\n",
    "delay_imp[\"imputed\"] = delay_imp[\"imputation\"]!=\"original\"\n",
    "delay_imp[\"date_onset\"] = pd.to_datetime(\"2020-01-01\")+pd.to_timedelta(delay_imp[\"day_onset\"],unit=\"days\")\n",
    "delay_imp[\"week_onset\"] = delay_imp[\"date_onset\"].dt.week\n",
    "delay_imp[\"weekday_onset\"] = as_ordered_weekday(delay_imp[\"date_onset\"].dt.day_name())\n",
    "delay_imp[\"reporting_delay_hd\"]=delay_imp[\"day_report\"]-delay_imp[\"day_onset\"]\n",
    "delay_imp[\"reporting_delay_rki\"]=delay_imp[\"day_report_rki\"]-delay_imp[\"day_onset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add observations with negative reporting delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_final = pd.concat([delay_imp,delay_neg.assign(imputation=\"original\",imputed=False)],sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export imputed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Exporting as CSV.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Exporting as CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp in delay_final[\"imputation\"].unique():\n",
    "    if imp!=\"original\":\n",
    "        delay_final.query(f\"imputation=='original' | imputation=='{imp}'\").to_csv(f\"../../data/processed/{filename}_{imp}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:IMPUTATION:Exporting as pickle.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Exporting as pickle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp in delay_final[\"imputation\"].unique():\n",
    "    if imp!=\"original\":\n",
    "        delay_final.query(f\"imputation=='original' | imputation=='{imp}'\").to_pickle(f\"../../data/processed/{filename}_{imp}.pl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda4841bd74195e4398914578314ee45bf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
