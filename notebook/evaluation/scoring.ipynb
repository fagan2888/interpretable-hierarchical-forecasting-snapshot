{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_score(observations, alpha, q_dict=None, q_left=None, q_right=None, check_consistency=True):\n",
    "    \"\"\"\n",
    "    Compute interval scores (aka quantile scores) for an array of observations and predicted intervals.\n",
    "    \n",
    "    Either a dictionary with the respective (alpha/2) and (1-(alpha/2)) quantiles via q_dict needs to be\n",
    "    specified or the quantiles need to be specified via q_left and q_right.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : array_like\n",
    "        Ground truth observations.\n",
    "    alpha : numeric\n",
    "        Alpha level for (1-alpha) interval.\n",
    "    q_dict : dict, optional\n",
    "        Dictionary with predicted quantiles for all instances in `observations`.\n",
    "    q_left : array_like, optional\n",
    "        Predicted (alpha/2)-quantiles for all instances in `observations`.\n",
    "    q_right : array_like, optional\n",
    "        Predicted (1-(alpha/2))-quantiles for all instances in `observations`.\n",
    "    check_consistency: bool, optional\n",
    "        If `True`, quantiles in `q_dict` are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total : array_like\n",
    "        Total interval scores.\n",
    "    sharpness : array_like\n",
    "        Sharpness component of interval scores.\n",
    "    calibration : array_like\n",
    "        Calibration component of interval scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    if q_dict is None:\n",
    "        if q_left is None or q_right is None:\n",
    "            raise ValueError(\"Either quantile dictionary or left and right quantile must be supplied.\")\n",
    "    else:       \n",
    "        if q_left is not None or q_right is not None:\n",
    "            raise ValueError(\"Either quantile dictionary OR left and right quantile must be supplied, not both.\")\n",
    "        q_left = q_dict.get(alpha/2)\n",
    "        if q_left is None: raise ValueError(f\"Quantile dictionary does not include {alpha/2}-quantile\")\n",
    "        \n",
    "        q_right = q_dict.get(1-(alpha/2))\n",
    "        if q_right is None: raise ValueError(f\"Quantile dictionary does not include {1-(alpha/2)}-quantile\")          \n",
    "    \n",
    "    if check_consistency and np.any(q_left>q_right): raise ValueError(\"Left quantile must be smaller than right quantile.\") \n",
    "        \n",
    "    sharpness = q_right-q_left\n",
    "    calibration = (np.clip(q_left-observations,a_min=0,a_max=None) + np.clip(observations-q_right,a_min=0,a_max=None)) * 2 / alpha\n",
    "    total = sharpness + calibration\n",
    "    return total, sharpness, calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Interval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_interval_score(observations, alphas, q_dict, weights=None, check_consistency=True):\n",
    "    \"\"\"\n",
    "    Compute weighted interval scores for an array of observations and a number of different predicted intervals.\n",
    "    \n",
    "    This function implements the new WIS-score by Johannes Bracher. A dictionary with the respective (alpha/2)\n",
    "    and (1-(alpha/2)) quantiles for all alpha levels given in `alphas` needs to be specified.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : array_like\n",
    "        Ground truth observations.\n",
    "    alphas : iterable\n",
    "        Alpha levels for (1-alpha) intervals.\n",
    "    q_dict : dict\n",
    "        Dictionary with predicted quantiles for all instances in `observations`.\n",
    "    weights : iterable, optional\n",
    "        Corresponding weights for each interval. If `None`, `weights` is set to `alphas`, yielding the WIS^alpha-score.\n",
    "    check_consistency: bool, optional\n",
    "        If `True`, quantiles in `q_dict` are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total : array_like\n",
    "        Total weighted interval scores.\n",
    "    sharpness : array_like\n",
    "        Sharpness component of weighted interval scores.\n",
    "    calibration : array_like\n",
    "        Calibration component of weighted interval scores.\n",
    "    \"\"\"\n",
    "    if weights is None: weights = alphas\n",
    "    \n",
    "    def weigh_scores(tuple_in,weight):\n",
    "        return tuple_in[0]*weight,tuple_in[1]*weight,tuple_in[2]*weight\n",
    "    \n",
    "    interval_scores = [i for i in zip(*[weigh_scores(interval_score(observations,alpha,q_dict=q_dict,check_consistency=check_consistency),weight) for alpha,weight in zip(alphas,weights)])]\n",
    "    \n",
    "    total = np.sum(np.vstack(interval_scores[0]),axis=0)/sum(weights)\n",
    "    sharpness = np.sum(np.vstack(interval_scores[1]),axis=0)/sum(weights)\n",
    "    calibration = np.sum(np.vstack(interval_scores[2]),axis=0)/sum(weights)\n",
    "    \n",
    "    return total, sharpness, calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_interval_score_fast(observations, alphas, q_dict, weights=None, check_consistency=True):\n",
    "    \"\"\"\n",
    "    Compute weighted interval scores for an array of observations and a number of different predicted intervals.\n",
    "    \n",
    "    This function implements the new WIS-score by Johannes Bracher. A dictionary with the respective (alpha/2)\n",
    "    and (1-(alpha/2)) quantiles for all alpha levels given in `alphas` needs to be specified.\n",
    "    \n",
    "    This is a more efficient implementation using array operations instead of repeated calls of `interval_score`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : array_like\n",
    "        Ground truth observations.\n",
    "    alphas : iterable\n",
    "        Alpha levels for (1-alpha) intervals.\n",
    "    q_dict : dict\n",
    "        Dictionary with predicted quantiles for all instances in `observations`.\n",
    "    weights : iterable, optional\n",
    "        Corresponding weights for each interval. If `None`, `weights` is set to `alphas`, yielding the WIS^alpha-score.\n",
    "    check_consistency: bool, optional\n",
    "        If `True`, quantiles in `q_dict` are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total : array_like\n",
    "        Total weighted interval scores.\n",
    "    sharpness : array_like\n",
    "        Sharpness component of weighted interval scores.\n",
    "    calibration : array_like\n",
    "        Calibration component of weighted interval scores.\n",
    "    \"\"\"\n",
    "    if weights is None: weights = alphas\n",
    "    \n",
    "    if not all(alphas[i] <= alphas[i+1] for i in range(len(alphas)-1)): raise ValueError(\"Alpha values must be sorted in ascending order.\")\n",
    "    \n",
    "    reversed_weights = list(reversed(weights))\n",
    "    \n",
    "    lower_quantiles = [q_dict.get(alpha/2) for alpha in alphas]\n",
    "    upper_quantiles = [q_dict.get(1-(alpha/2)) for alpha in reversed(alphas)]\n",
    "    if any(q is None for q in lower_quantiles) or any(q is None for q in upper_quantiles):\n",
    "        raise ValueError(f\"Quantile dictionary does not include all necessary quantiles.\")\n",
    "    \n",
    "    lower_quantiles = np.vstack(lower_quantiles)\n",
    "    upper_quantiles = np.vstack(upper_quantiles)\n",
    "    \n",
    "    # Check for consistency\n",
    "    if check_consistency and np.any(np.diff(np.vstack((lower_quantiles,upper_quantiles)),axis=0)<0):\n",
    "            raise ValueError(\"Quantiles are not consistent.\")\n",
    "    \n",
    "    lower_q_alphas = (2 / np.array(alphas)).reshape((-1,1))\n",
    "    upper_q_alphas = (2 / np.array(list(reversed(alphas)))).reshape((-1,1))\n",
    "    \n",
    "    # compute score components for all intervals\n",
    "    sharpnesses = (np.flip(upper_quantiles,axis=0) - lower_quantiles)\n",
    "    \n",
    "    lower_calibrations = np.clip(lower_quantiles-observations,a_min=0,a_max=None) * lower_q_alphas\n",
    "    upper_calibrations = np.clip(observations-upper_quantiles,a_min=0,a_max=None) * upper_q_alphas\n",
    "    calibrations = lower_calibrations + np.flip(upper_calibrations,axis=0)\n",
    "    \n",
    "    totals = sharpnesses + calibrations\n",
    "    \n",
    "    # weigh scores\n",
    "    weights = np.array(weights).reshape((-1,1))\n",
    "    \n",
    "    sharpnesses_weighted = sharpnesses * weights\n",
    "    calibrations_weighted = calibrations * weights\n",
    "    totals_weighted = totals * weights\n",
    "    \n",
    "    # normalize and aggregate all interval scores\n",
    "    weights_sum = np.sum(weights)\n",
    "    \n",
    "    sharpnesses_final = np.sum(sharpnesses_weighted,axis=0) / weights_sum\n",
    "    calibrations_final = np.sum(calibrations_weighted,axis=0) / weights_sum\n",
    "    totals_final = np.sum(totals_weighted,axis=0) / weights_sum\n",
    "    \n",
    "    return totals_final, sharpnesses_final, calibrations_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside-Interval Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outside_interval(observations, lower, upper, check_consistency=True):\n",
    "    \"\"\"\n",
    "    Indicate whether observations are outside a predicted interval for an array of observations and predicted intervals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : array_like\n",
    "        Ground truth observations.\n",
    "    lower : array_like, optional\n",
    "        Predicted lower interval boundary for all instances in `observations`.\n",
    "    upper : array_like, optional\n",
    "        Predicted upper interval boundary for all instances in `observations`.\n",
    "    check_consistency: bool, optional\n",
    "        If `True`, interval boundaries are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Out : array_like\n",
    "        Array of zeroes (False) and ones (True) counting the number of times observations where outside the interval.\n",
    "    \"\"\"\n",
    "    if check_consistency and np.any(lower>upper): raise ValueError(\"Lower border must be smaller than upper border.\")\n",
    "        \n",
    "    return ((lower>observations) + (upper<observations)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval Consistency Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_consistency_score(lower_old, upper_old, lower_new, upper_new, check_consistency=True):\n",
    "    \"\"\"\n",
    "    Compute interval consistency scores for an old and a new interval.\n",
    "    \n",
    "    Adapted variant of the interval score which measures the consistency of updated intervals over time.\n",
    "    Ideally, updated predicted intervals would always be within the previous estimates of the interval, yielding\n",
    "    a score of zero (best).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lower_old : array_like\n",
    "        Previous lower interval boundary for all instances in `observations`.\n",
    "    upper_old : array_like, optional\n",
    "        Previous upper interval boundary for all instances in `observations`.\n",
    "    lower_new : array_like\n",
    "        New lower interval boundary for all instances in `observations`. Ideally higher than the previous boundary.\n",
    "    upper_new : array_like, optional\n",
    "        New upper interval boundary for all instances in `observations`. Ideally lower than the previous boundary.\n",
    "    check_consistency: bool, optional\n",
    "        If interval boundaries are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    scores : array_like\n",
    "        Interval consistency scores.\n",
    "    \"\"\"\n",
    "    if check_consistency and (np.any(lower_old>upper_old) or np.any(lower_new>upper_new)): raise ValueError(\"Left quantile must be smaller than right quantile.\") \n",
    "        \n",
    "    scores = np.clip(lower_old-lower_new,a_min=0,a_max=None) + np.clip(upper_new-upper_old,a_min=0,a_max=None)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE and sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_score(observations, point_forecasts):\n",
    "    return 100 * np.abs(point_forecasts - observations) / np.abs(observations)\n",
    "\n",
    "def smape_score(observations, point_forecasts):\n",
    "    return 100 * (2 * np.abs(point_forecasts - observations) / (np.abs(observations) + np.abs(point_forecasts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_to_predictive(point_forecasts, lower_ci, upper_ci, alpha, quantiles, dist=\"norm\"):\n",
    "    if dist==\"norm\":\n",
    "        norm_sd_lower = (point_forecasts - lower_ci)/norm.ppf(1-alpha/2)\n",
    "        norm_sd_upper = (upper_ci - point_forecasts)/norm.ppf(1-alpha/2)\n",
    "        norm_sd = (norm_sd_lower + norm_sd_upper)/2 # average\n",
    "        \n",
    "        return np.array([[norm.ppf(q,loc=point,scale=stdev) for q in quantiles] for point,stdev in zip(point_forecasts,norm_sd)])\n",
    "    else:\n",
    "        raise ValueError(f\"Distribution {norm} not implemented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    observations_test = np.array([4,7,4,6,2,1,3,8])\n",
    "    q_10_test = np.array([2,3,5,9,1,-3,0.2,8.7])\n",
    "    q_90_test = np.array([5,5,7,13,5,-1,3,9])\n",
    "    alpha_test=0.2\n",
    "    quantile_dict_test = {\n",
    "        0.1: np.array([2, 3  , 5  , 9  , 1  , -3  , 0.2, 8.7]),\n",
    "        0.2: np.array([2, 4.6, 5  , 9.4, 1.4, -2  , 0.4, 8.8]),\n",
    "        0.8: np.array([4, 4.8, 5.7, 12 , 4.3, -1.5, 2  , 8.9]),\n",
    "        0.9: np.array([5, 5  , 7  , 13 , 5  , -1  , 3  , 9])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3. , 22. , 12. , 34. ,  4. , 22. ,  2.8,  7.3]), array([3. , 2. , 2. , 4. , 4. , 2. , 2.8, 0.3]), array([ 0., 20., 10., 30.,  0., 20.,  0.,  7.]))\n",
      "(array([ 3. , 22. , 12. , 34. ,  4. , 22. ,  2.8,  7.3]), array([3. , 2. , 2. , 4. , 4. , 2. , 2.8, 0.3]), array([ 0., 20., 10., 30.,  0., 20.,  0.,  7.]))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(interval_score(observations_test,alpha_test,q_left=q_10_test,q_right=q_90_test))\n",
    "    print(interval_score(observations_test,alpha_test,q_dict=quantile_dict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Interval Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 2.28571429, 14.28571429,  7.5       , 23.71428571,  3.21428571,\n",
      "       15.57142857,  5.51428571,  5.01428571]), array([2.28571429, 0.71428571, 1.07142857, 3.        , 3.21428571,\n",
      "       0.92857143, 1.94285714, 0.15714286]), array([ 0.        , 13.57142857,  6.42857143, 20.71428571,  0.        ,\n",
      "       14.64285714,  3.57142857,  4.85714286]))\n",
      "(array([ 2.28571429, 14.28571429,  7.5       , 23.71428571,  3.21428571,\n",
      "       15.57142857,  5.51428571,  5.01428571]), array([2.28571429, 0.71428571, 1.07142857, 3.        , 3.21428571,\n",
      "       0.92857143, 1.94285714, 0.15714286]), array([ 0.        , 13.57142857,  6.42857143, 20.71428571,  0.        ,\n",
      "       14.64285714,  3.57142857,  4.85714286]))\n",
      "(array([ 2.33333333, 14.8       ,  7.8       , 24.4       ,  3.26666667,\n",
      "       16.        ,  5.33333333,  5.16666667]), array([2.33333333, 0.8       , 1.13333333, 3.06666667, 3.26666667,\n",
      "       1.        , 2.        , 0.16666667]), array([ 0.        , 14.        ,  6.66666667, 21.33333333,  0.        ,\n",
      "       15.        ,  3.33333333,  5.        ]))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(weighted_interval_score(observations_test,alphas=[0.2,0.4],weights=[2,5],q_dict=quantile_dict_test))\n",
    "          \n",
    "    print(weighted_interval_score_fast(observations_test,alphas=[0.2,0.4],weights=[2,5],q_dict=quantile_dict_test)) \n",
    "    \n",
    "    #WIS^alpha score\n",
    "    print(weighted_interval_score_fast(observations_test,alphas=[0.2,0.4],weights=None,q_dict=quantile_dict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare runtimes of weighted interval score methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.0064390999996248866, 5: 0.01210960000025807, 10: 0.021654099999977916, 20: 0.0410543999996662}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print({n: min(timeit.repeat(lambda: weighted_interval_score(observations_test,alphas=[0.2]*n,weights=None,q_dict=quantile_dict_test),repeat=100,number=100)) for n in [2,5,10,20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.008584199999859266, 5: 0.00853370000004361, 10: 0.008546499999283697, 20: 0.00851909999983036, 40: 0.008594199999606644, 80: 0.008528399999704561}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print({n: min(timeit.repeat(lambda: weighted_interval_score_fast(observations_test,alphas=[0.2]*2,weights=None,q_dict=quantile_dict_test),repeat=100,number=100)) for n in [2,5,10,20,40,80]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the fast implementation is in fact quicker for more than 2 or 3 intervals. It stays almost constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Interval Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(outside_interval(observations_test,lower=q_10_test,upper=q_90_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval Consistency Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    interval_consistency_score(quantile_dict_test[0.1],quantile_dict_test[0.9],quantile_dict_test[0.1],quantile_dict_test[0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.2, 1.3, 1. , 0.7, 0.5, 1. , 0.1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    interval_consistency_score(quantile_dict_test[0.1],quantile_dict_test[0.8],quantile_dict_test[0.1],quantile_dict_test[0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 296.15762316,  298.99414424,  300.90793154,  302.42894902,\n",
       "         303.73384658,  304.90568493,  305.99156779,  307.02196444,\n",
       "         308.01888512,  309.        ,  309.98111488,  310.97803556,\n",
       "         312.00843221,  313.09431507,  314.26615342,  315.57105098,\n",
       "         317.09206846,  319.00585576,  321.84237684],\n",
       "       [ 314.52454822,  317.28002583,  319.1391335 ,  320.61669333,\n",
       "         321.88430811,  323.02266536,  324.077523  ,  325.07847974,\n",
       "         326.04691697,  327.        ,  327.95308303,  328.92152026,\n",
       "         329.922477  ,  330.97733464,  332.11569189,  333.38330667,\n",
       "         334.8608665 ,  336.71997417,  339.47545178],\n",
       "       [ 436.95607285,  440.27885468,  442.52071981,  444.30248314,\n",
       "         445.83107743,  447.20380234,  448.47583655,  449.68287263,\n",
       "         450.850694  ,  452.        ,  453.149306  ,  454.31712737,\n",
       "         455.52416345,  456.79619766,  458.16892257,  459.69751686,\n",
       "         461.47928019,  463.72114532,  467.04392715],\n",
       "       [ 478.38759748,  482.27768353,  484.90230611,  486.98827294,\n",
       "         488.77784675,  490.38493933,  491.87415011,  493.28726551,\n",
       "         494.65447102,  496.        ,  497.34552898,  498.71273449,\n",
       "         500.12584989,  501.61506067,  503.22215325,  505.01172706,\n",
       "         507.09769389,  509.72231647,  513.61240252],\n",
       "       [ 743.08527201,  747.70474919,  750.82148851,  753.29857412,\n",
       "         755.42369301,  757.33211545,  759.10055326,  760.7786278 ,\n",
       "         762.40218434,  764.        ,  765.59781566,  767.2213722 ,\n",
       "         768.89944674,  770.66788455,  772.57630699,  774.70142588,\n",
       "         777.17851149,  780.29525081,  784.91472799],\n",
       "       [ 971.6175718 ,  976.56122281,  979.89668069,  982.54759687,\n",
       "         984.82184691,  986.86419373,  988.75673243,  990.55256659,\n",
       "         992.29005692,  994.        ,  995.70994308,  997.44743341,\n",
       "         999.24326757, 1001.13580627, 1003.17815309, 1005.45240313,\n",
       "        1008.10331931, 1011.43877719, 1016.3824282 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    points = np.array([309,327,452,496,764,994])\n",
    "    lower = np.array([293,309,433,475,741,968])\n",
    "    upper = np.array([328,343,474,523,798,1029])\n",
    "    confidence_to_predictive(points,lower,upper,alpha=0.025,quantiles=np.arange(0.05,1,0.05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda4841bd74195e4398914578314ee45bf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
